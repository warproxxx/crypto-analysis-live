{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "from glob import glob\n",
    "import os\n",
    "import swifter\n",
    "import shutil\n",
    "\n",
    "import tweepy\n",
    "from ttp import ttp\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "from calendar import timegm\n",
    "\n",
    "from utils.casIn.user_influence import P,influence\n",
    "from utils.common_utils import get_root_dir, merge_csvs\n",
    "from utils.twitter_authentication import *\n",
    "from utils.profilescraper import profileScraper\n",
    "from process import create_cascades, processor, process_scraped_profile, get_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = get_root_dir()\n",
    "storagefolder = os.path.join(dir, 'data/storage/all_cleaned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "storagesfiles = glob(storagefolder + \"/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = merge_csvs(storagesfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/warproxxx/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (0,1,2,3,6,7,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Time'] = pd.to_datetime(df['Time'])\n",
    "# #time wrong here but is correct actually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[80000:120000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_cascades(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values('Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df['cascade'].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_count = counts[counts['cascade'] > 3][['index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_existing = ids_count[~ids_count['index'].isin(df['ID'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_name():\n",
    "    fname = get_root_dir() + '/data/temp/rescraped.csv'\n",
    "\n",
    "    if os.path.isfile(fname):\n",
    "        pass\n",
    "    else:\n",
    "        # create output file and add header\n",
    "        with open(fname, 'w') as csvfile:\n",
    "            writer = csv.writer(csvfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "            \n",
    "            header = ['timestamp','id','text','likes','retweets','username','user_id','user_created_at','in_response_to', \n",
    "                      'in_response_to_user_id', 'response_type', 'has_geolocation', 'is_verified', 'total_tweets', 'total_followers', \n",
    "                      'total_following', 'total_likes', 'total_lists', 'has_background', 'is_protected', 'default_profile']\n",
    "            \n",
    "            writer.writerow(header)\n",
    "    \n",
    "    return fname\n",
    "\n",
    "def write_csv(row_data):\n",
    "    filename = get_file_name()\n",
    "\n",
    "    with open(filename, 'a') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        writer.writerow(row_data)\n",
    "\n",
    "def make_tweets(find_id, original):\n",
    "    #fix this error\n",
    "    found = original[original['in_response_to_id'] == find_id]\n",
    "    p = ttp.Parser()\n",
    "    parsed = p.parse(found.iloc[0]['Tweet'])\n",
    "    \n",
    "    current_tweet = {}\n",
    "    \n",
    "    current_tweet['ID'] = found.iloc[0].in_response_to_id\n",
    "    current_tweet['Tweet'] = found.iloc[0].Tweet\n",
    "    current_tweet['Time'] = found.iloc[0].Time - (found.iloc[1].Time - found.iloc[0].Time)\n",
    "    try:\n",
    "        current_tweet['User'] = parsed.users[0]\n",
    "    except:\n",
    "        current_tweet['User'] = ''\n",
    "    current_tweet['Likes'] = 0\n",
    "    current_tweet['Retweets'] = 0\n",
    "    current_tweet['in_response_to_id'] = 0\n",
    "    current_tweet['response_type'] = 'tweet'\n",
    "    \n",
    "    return pd.Series(current_tweet)\n",
    "\n",
    "def rescrape_and_add(original, to_scrape):\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_key, access_secret)\n",
    "    api = tweepy.API(auth)\n",
    "\n",
    "    print(\"Rescraping {} tweets\".format(len(to_scrape)))\n",
    "    for i in range(100, len(to_scrape)+100, 100):\n",
    "        print(\"{} {}\".format(i-100, i))\n",
    "        \n",
    "        tweets = api.statuses_lookup(list(to_scrape['index'][i-100:i].values),tweet_mode='extended')\n",
    "        \n",
    "        for tweet in     tweets:\n",
    "            response_type = 'tweet'\n",
    "            in_response_to = None\n",
    "\n",
    "            try:\n",
    "                in_response_to = tweet.in_reply_to_status_id\n",
    "                in_response_to_user_id = tweet.in_reply_to_user_id_str\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            if in_response_to == None:\n",
    "                if hasattr(tweet, 'retweeted_status'):\n",
    "                    response_type = 'retweet'\n",
    "                    in_response_to = tweet.retweeted_status.id\n",
    "                    in_response_to_user_id = tweet.retweeted_status.user._json['id_str'] #probably not required\n",
    "                else:\n",
    "                    if hasattr(tweet, 'quoted_status'):\n",
    "                        response_type = 'quoted_retweet'\n",
    "                        in_response_to = tweet.quoted_status.id\n",
    "                        in_response_to_user_id = tweet.quoted_status.user._json['id_str'] #probably not required\n",
    "                    else:\n",
    "                        in_response_to = '0'\n",
    "            else:\n",
    "                response_type = 'reply'\n",
    "\n",
    "\n",
    "            tweetText = ''\n",
    "            try:\n",
    "                tweetText = tweetText + tweet.extended_tweet['full_text']\n",
    "            except:\n",
    "                try:\n",
    "                    tweetText = tweetText + tweet.full_text\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            try:\n",
    "                tweetText = tweetText + ' <retweeted_status> ' + tweet.retweeted_status.extended_tweet['full_text'] + ' </retweeted_status>'\n",
    "            except:\n",
    "                try:\n",
    "                    tweetText = tweetText + ' <retweeted_status> ' + tweet.retweeted_status.text + ' </retweeted_status>'\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            try:\n",
    "                tweetText = tweetText + ' <quoted_status> ' + tweet.quoted_status.extended_tweet['full_text'] + ' </quoted_status>'\n",
    "            except:\n",
    "                try:\n",
    "                    tweetText = tweetText + ' <quoted_status> ' + tweet.quoted_status.text + ' </quoted_status>'\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            if 'urls' in tweet.entities:\n",
    "                for url in tweet.entities['urls']:\n",
    "                    try:\n",
    "                        tweetText = tweetText.replace(url['url'], url['expanded_url'])\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "            write_csv([tweet.created_at, tweet.id, tweetText, tweet.favorite_count, tweet.retweet_count,            \n",
    "            tweet.user.screen_name, tweet.user._json['id_str'], tweet.user._json['created_at'],in_response_to, \n",
    "            in_response_to_user_id ,response_type, tweet.user.geo_enabled, tweet.user.verified, tweet.user.statuses_count, \n",
    "            tweet.user.followers_count, tweet.user.friends_count, tweet.user.favourites_count, tweet.user.listed_count\n",
    "            ,tweet.user.profile_use_background_image, tweet.user.protected, tweet.user.default_profile])\n",
    "\n",
    "    \n",
    "    rescraped = pd.read_csv(get_root_dir() + '/data/temp/rescraped.csv')\n",
    "    profile = pd.read_csv(os.path.join(get_root_dir(), 'data/cleaned_profile.csv'))\n",
    "    \n",
    "    original['Time'] = pd.to_datetime(original['Time'])\n",
    "\n",
    "    original['Time'] = original['Time'].astype(int) // 10**9\n",
    "    rescraped_df, rescraped_profile = processor(rescraped)\n",
    "    non_existing = to_scrape[~to_scrape['index'].isin(rescraped['id'])]\n",
    "\n",
    "    virtual_tweets = non_existing['index'].apply(make_tweets, original=original)\n",
    "    rescraped = pd.concat([virtual_tweets, rescraped_df]).reset_index(drop=True)\n",
    "    virtual_tweets['User'] = virtual_tweets['User'].str.lower()\n",
    "    rescrape = virtual_tweets[~virtual_tweets['User'].isin(profile['username'])]\n",
    "    ps = profileScraper()\n",
    "    scraped = ps.query_profile(rescrape['User'].values)\n",
    "    scraped_profile = process_scraped_profile(scraped)\n",
    "\n",
    "    new_profile = pd.concat([scraped_profile, rescraped_profile, profile]) #clean them seperately before concating\n",
    "    new_profile = new_profile.drop_duplicates(subset=['username']).reset_index(drop=True)\n",
    "    new_profile.to_csv(os.path.join(get_root_dir(), 'data/cleaned_profile.csv'), index=None)\n",
    "\n",
    "    rescraped = get_sentiment(rescraped)\n",
    "    new_df = pd.concat([original, rescraped])\n",
    "    new_df = new_df.sort_values('Time')\n",
    "\n",
    "    return new_df, new_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rescraping 525 tweets\n",
      "0 100\n",
      "100 200\n",
      "200 300\n",
      "300 400\n",
      "400 500\n",
      "500 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/warproxxx/Desktop/Projects/crypto-analysis-live/algorithm/process.py:94: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
      "/home/warproxxx/Desktop/Projects/crypto-analysis-live/algorithm/process.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['timestamp'] = df['timestamp'].astype(np.int64) // 10**9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying https://twitter.com/skrillscam\n",
      "Querying https://twitter.com/btsvoti39627642\n",
      "Querying https://twitter.com/\n",
      "Got an error scraping: 'profile_user'\n",
      "Got 1 profiles (1 new).\n",
      "Got an error scraping: 'NoneType' object is not subscriptable\n",
      "Got 2 profiles (1 new).\n",
      "Got an error scraping: 'profile_user'\n",
      "Got 3 profiles (1 new).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/warproxxx/Desktop/Projects/crypto-analysis-live/algorithm/process.py:192: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  cop.to_csv(tempFile, index=None, header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java -jar /home/warproxxx/Desktop/Projects/crypto-analysis-live/algorithm/utils/SentiStrength.jar sentidata /home/warproxxx/Desktop/Projects/crypto-analysis-live/algorithm/utils/SentiStrength_Data/ input /home/warproxxx/Desktop/Projects/crypto-analysis-live/algorithm/data/temp/tweets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/warproxxx/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:146: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df, profile = rescrape_and_add(df, non_existing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(profile[['username', 'total_followers']], left_on='User', right_on='username', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'Time': 'time', 'total_followers': 'magnitude', 'User': 'user_id'})\n",
    "counts = df['cascade'].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['cascade'].isin(counts[counts['cascade'] > 2]['index'])]\n",
    "oldcascade_file = os.path.join(dir, 'data/storage/old_cascade.csv')\n",
    "df = df[['ID', 'time', 'magnitude', 'user_id', 'cascade']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type \"<class 'str'>\"; only pd.Series, pd.DataFrame, and pd.Panel (deprecated) objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-55f6724bce39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moldcascade_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moldcascade_file\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    226\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                        copy=copy, sort=sort)\n\u001b[0m\u001b[1;32m    229\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    287\u001b[0m                        \u001b[0;34m' only pd.Series, pd.DataFrame, and pd.Panel'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                        ' (deprecated) objs are valid'.format(type(obj)))\n\u001b[0;32m--> 289\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;31m# consolidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot concatenate object of type \"<class 'str'>\"; only pd.Series, pd.DataFrame, and pd.Panel (deprecated) objs are valid"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(oldcascade_file):\n",
    "    old_file = pd.read_csv(oldcascade_file)\n",
    "    old_file = old_file[old_file['cascade'].isin(df['cascade'])]\n",
    "    df.to_csv(oldcascade_file, index=None)\n",
    "\n",
    "    df = pd.concat([df, old_file])\n",
    "    df = df.reset_index()\n",
    "else:\n",
    "    df.to_csv(oldcascade_file, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_influence(df):\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    p_ij = P(df,r = -0.000068)\n",
    "    inf, m_ij = influence(p_ij)\n",
    "    df['inf'] = inf\n",
    "    df = df[['ID', 'inf', 'cascade']]\n",
    "    return df\n",
    "\n",
    "def get_influence_metrics(df):\n",
    "    curr = {}\n",
    "    curr['total_tweets'] = len(df)\n",
    "    curr['total_influence'] = df['inf'].sum()\n",
    "    curr['avg_influence'] = curr['total_tweets'] / curr['total_influence']\n",
    "             \n",
    "    return pd.Series(curr)\n",
    "\n",
    "def add_influence_and_all(df):\n",
    "    d = df.groupby('cascade').apply(get_influence)\n",
    "    d = d.drop_duplicates()\n",
    "    df = df.merge(d, on='ID')\n",
    "    df = df.drop('cascade_y', axis=1).rename(columns={'cascade_x':'cascade'})\n",
    "    new_inf = df.groupby('user_id').apply(get_influence_metrics)\n",
    "\n",
    "    new_inf = new_inf.reset_index().rename(columns={'user_id': 'username'})\n",
    "    return new_inf\n",
    "\n",
    "def add_inf(curr_inf, new_inf):\n",
    "    combined = new_inf.merge(curr_inf, how='outer', on='username')\n",
    "    combined = combined.fillna(0)\n",
    "    combined['total_tweets'] = combined['total_tweets_x'] + combined['total_tweets_y']\n",
    "    combined['total_influence'] = combined['total_influence_x'] + combined['total_influence_y']\n",
    "    combined = combined[['username', 'total_tweets', 'total_influence']]\n",
    "    combined['avg_influence'] = combined['total_influence']/combined['total_tweets']\n",
    "    combined.sort_values('total_influence', ascending=False)\n",
    "    \n",
    "    return combined\n",
    "\n",
    "def sub_inf(combined_inf, to_remove):\n",
    "    combined = combined_inf.merge(to_remove, how='outer', on='username')\n",
    "    combined = combined.fillna(0)\n",
    "    combined['total_tweets'] = combined['total_tweets_x'] - combined['total_tweets_y']\n",
    "    combined['total_influence'] = combined['total_influence_x'] - combined['total_influence_y']\n",
    "    combined = combined[['username', 'total_tweets', 'total_influence']]\n",
    "    combined['avg_influence'] = combined['total_influence']/combined['total_tweets']\n",
    "    combined.sort_values('total_influence', ascending=False)\n",
    "    \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_inf = add_influence_and_all(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_inf = pd.read_csv(os.path.join(dir, 'data/userwise_influence.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_inf = add_inf(curr_inf, new_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "if 'old_file' in locals():\n",
    "    to_remove = add_influence_and_all(old_file.drop('inf', axis=1))\n",
    "    combined_inf = sub_inf(combined_inf, to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>total_tweets</th>\n",
       "      <th>total_influence</th>\n",
       "      <th>avg_influence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>004mia2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.334482</td>\n",
       "      <td>1.334482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01001001_i</td>\n",
       "      <td>39.0</td>\n",
       "      <td>67.286921</td>\n",
       "      <td>1.725306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02_ilonka</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02_sochie</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04gtp</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.948235</td>\n",
       "      <td>6.987059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0566mis</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.004695</td>\n",
       "      <td>1.001174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>099_roody</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.712537</td>\n",
       "      <td>1.356268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0bangtan_boys93</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.190924</td>\n",
       "      <td>1.190924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0d5994eb54f748f</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0daisyflower0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.057310</td>\n",
       "      <td>1.057310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0hoeschris</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.513219</td>\n",
       "      <td>1.128305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0knowledgeactor</td>\n",
       "      <td>50.0</td>\n",
       "      <td>119.012157</td>\n",
       "      <td>2.380243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0r161n4lh4ck3r</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0rcablue</td>\n",
       "      <td>22.0</td>\n",
       "      <td>39.216409</td>\n",
       "      <td>1.782564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0wnowzz</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.096901</td>\n",
       "      <td>1.019380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0x722</td>\n",
       "      <td>15.0</td>\n",
       "      <td>144.266153</td>\n",
       "      <td>9.617744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0xdufeau</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.158376</td>\n",
       "      <td>1.010558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0xownsupdates</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100019co2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1001trending</td>\n",
       "      <td>27.0</td>\n",
       "      <td>131.309528</td>\n",
       "      <td>4.863316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>101blockchainst</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>101percent_in</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.017149</td>\n",
       "      <td>1.002144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10dtozzi</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.218822</td>\n",
       "      <td>1.369804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>116arii</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11_11_______</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>11juman11</td>\n",
       "      <td>12.0</td>\n",
       "      <td>393.405437</td>\n",
       "      <td>32.783786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>123ilnur</td>\n",
       "      <td>20.0</td>\n",
       "      <td>26.527285</td>\n",
       "      <td>1.326364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>130613___twt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.093861</td>\n",
       "      <td>1.093861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>130613ast</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.720162</td>\n",
       "      <td>1.430040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>131095_jm</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358913</th>\n",
       "      <td>marjessa4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358914</th>\n",
       "      <td>freddy_jc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358915</th>\n",
       "      <td>freddyyork88</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358916</th>\n",
       "      <td>fredebenvina</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358917</th>\n",
       "      <td>shreyas983</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358918</th>\n",
       "      <td>fredericbeaupre</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358919</th>\n",
       "      <td>shreyans2788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358920</th>\n",
       "      <td>frederichie</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358921</th>\n",
       "      <td>shreyadhoundial</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358922</th>\n",
       "      <td>marjolaineviret</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358923</th>\n",
       "      <td>freddy_fred1084</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358924</th>\n",
       "      <td>frecklefacehan</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358925</th>\n",
       "      <td>shriramkrishnan</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358926</th>\n",
       "      <td>fred1boot</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358927</th>\n",
       "      <td>fred51984689</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358928</th>\n",
       "      <td>fred9455</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358929</th>\n",
       "      <td>shrishtripath18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358930</th>\n",
       "      <td>shrishthi4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358931</th>\n",
       "      <td>marjoriermartin</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358932</th>\n",
       "      <td>fred_gspoerer</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358933</th>\n",
       "      <td>shriramemahesh</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358934</th>\n",
       "      <td>freddotdz</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358935</th>\n",
       "      <td>fredcar21691250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358936</th>\n",
       "      <td>marjori86691698</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358937</th>\n",
       "      <td>shrimpville</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358938</th>\n",
       "      <td>freddie72t</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358939</th>\n",
       "      <td>freddiecee</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358940</th>\n",
       "      <td>freddieyours</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358941</th>\n",
       "      <td>freddmannen</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358942</th>\n",
       "      <td>natboogie_</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>358943 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               username  total_tweets  total_influence  avg_influence\n",
       "0               004mia2           1.0         1.334482       1.334482\n",
       "1            01001001_i          39.0        67.286921       1.725306\n",
       "2             02_ilonka           1.0         1.000000       1.000000\n",
       "3             02_sochie           1.0         1.000000       1.000000\n",
       "4                 04gtp           4.0        27.948235       6.987059\n",
       "5               0566mis           4.0         4.004695       1.001174\n",
       "6             099_roody           2.0         2.712537       1.356268\n",
       "7       0bangtan_boys93           1.0         1.190924       1.190924\n",
       "8       0d5994eb54f748f           1.0         1.000000       1.000000\n",
       "9         0daisyflower0           1.0         1.057310       1.057310\n",
       "10           0hoeschris           4.0         4.513219       1.128305\n",
       "11      0knowledgeactor          50.0       119.012157       2.380243\n",
       "12       0r161n4lh4ck3r           1.0         1.000000       1.000000\n",
       "13             0rcablue          22.0        39.216409       1.782564\n",
       "14              0wnowzz           5.0         5.096901       1.019380\n",
       "15                0x722          15.0       144.266153       9.617744\n",
       "16             0xdufeau          15.0        15.158376       1.010558\n",
       "17        0xownsupdates           2.0         2.000000       1.000000\n",
       "18            100019co2           1.0         1.000000       1.000000\n",
       "19         1001trending          27.0       131.309528       4.863316\n",
       "20      101blockchainst           5.0         5.000000       1.000000\n",
       "21        101percent_in           8.0         8.017149       1.002144\n",
       "22             10dtozzi           6.0         8.218822       1.369804\n",
       "23              116arii           1.0         1.000000       1.000000\n",
       "24         11_11_______           1.0         1.000000       1.000000\n",
       "25            11juman11          12.0       393.405437      32.783786\n",
       "26             123ilnur          20.0        26.527285       1.326364\n",
       "27         130613___twt           1.0         1.093861       1.093861\n",
       "28            130613ast           4.0         5.720162       1.430040\n",
       "29            131095_jm           1.0         1.000000       1.000000\n",
       "...                 ...           ...              ...            ...\n",
       "358913        marjessa4           1.0         1.000000       1.000000\n",
       "358914        freddy_jc           1.0         1.000000       1.000000\n",
       "358915     freddyyork88           1.0         1.000000       1.000000\n",
       "358916     fredebenvina           1.0         1.000000       1.000000\n",
       "358917       shreyas983           1.0         1.000000       1.000000\n",
       "358918  fredericbeaupre           1.0         1.000000       1.000000\n",
       "358919     shreyans2788           1.0         1.000000       1.000000\n",
       "358920      frederichie           1.0         1.000000       1.000000\n",
       "358921  shreyadhoundial           1.0         1.000000       1.000000\n",
       "358922  marjolaineviret           1.0         1.000000       1.000000\n",
       "358923  freddy_fred1084           1.0         1.000000       1.000000\n",
       "358924   frecklefacehan           1.0         1.000000       1.000000\n",
       "358925  shriramkrishnan           1.0         1.000000       1.000000\n",
       "358926        fred1boot           1.0         1.000000       1.000000\n",
       "358927     fred51984689           1.0         1.000000       1.000000\n",
       "358928         fred9455           1.0         1.000000       1.000000\n",
       "358929  shrishtripath18           1.0         1.000000       1.000000\n",
       "358930       shrishthi4           1.0         1.000000       1.000000\n",
       "358931  marjoriermartin           1.0         1.000000       1.000000\n",
       "358932    fred_gspoerer           1.0         1.000000       1.000000\n",
       "358933   shriramemahesh           1.0         1.000000       1.000000\n",
       "358934        freddotdz           1.0         1.000000       1.000000\n",
       "358935  fredcar21691250           1.0         1.000000       1.000000\n",
       "358936  marjori86691698           1.0         1.000000       1.000000\n",
       "358937      shrimpville           1.0         1.000000       1.000000\n",
       "358938       freddie72t           1.0         1.000000       1.000000\n",
       "358939       freddiecee           1.0         1.000000       1.000000\n",
       "358940     freddieyours           1.0         1.000000       1.000000\n",
       "358941      freddmannen           1.0         1.000000       1.000000\n",
       "358942       natboogie_           1.0         1.000000       1.000000\n",
       "\n",
       "[358943 rows x 4 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crypto-analysis",
   "language": "python",
   "name": "crypto-analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
